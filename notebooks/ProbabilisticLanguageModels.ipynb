{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de6340bd",
   "metadata": {},
   "source": [
    "#  Sustainable Prompt Optimization - Extended N-gram Language Modeling\n",
    "\n",
    "This notebook builds on the lab’s unigram and bigram work to add:\n",
    "\n",
    "- Trigram model (3-word sequences)\n",
    "- General N-gram counting\n",
    "- Interpolated sentence fluency scoring combining unigram, bigram, and trigram probabilities\n",
    "- Selecting the best candidate prompt based on interpolated scoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f24e5a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mathe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mathe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 📦 Setup and Imports (reuse from lab)\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e52005",
   "metadata": {},
   "source": [
    "#### Load the dataset from the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1bc148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus_from_file(filepath: str) -> str:\n",
    "    \"\"\"\n",
    "    Loads and returns the content of a text corpus from the given file path.\n",
    "\n",
    "    Parameters:\n",
    "    - filepath (str): Path to the text file containing the corpus.\n",
    "\n",
    "    Returns:\n",
    "    - str: The entire corpus as a single string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            corpus_text = file.read()\n",
    "        print(f\"✅ Successfully loaded corpus from: {filepath}\")\n",
    "        return corpus_text\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ File not found: {filepath}\")\n",
    "        return \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading corpus: {e}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e901f48",
   "metadata": {},
   "source": [
    "### 🧪 Tokenization & Normalization (reuse from lab)\n",
    "\n",
    "Lowercase, regex tokenization, stopword removal, and stemming.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f8ffe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenizer(text):\n",
    "    return re.findall(r'\\b\\w+\\b', text.lower())\n",
    "\n",
    "def normalize(tokens):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(word) for word in tokens if word not in stop_words and word not in string.punctuation]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a0289f",
   "metadata": {},
   "source": [
    "### 📚 Load & Preprocess Corpus\n",
    "\n",
    "Replace `sample_corpus` with your large corpus text content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08066050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded corpus from: ./data/corpus.txt\n"
     ]
    }
   ],
   "source": [
    "# Example placeholder corpus — replace with your large corpus text\n",
    "# sample_corpus = \"\"\"\n",
    "# Your large corpus text goes here. This should be a substantial text dataset.\n",
    "# It could be combined documents, articles, books, or any sizable textual material.\n",
    "# \"\"\"\n",
    "sample_corpus = load_corpus_from_file(\"./data/corpus.txt\")\n",
    "tokens = normalize(simple_tokenizer(sample_corpus))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c9aac6",
   "metadata": {},
   "source": [
    "### 🔢 Build N-Gram Counts: Unigram, Bigram, Trigram\n",
    "\n",
    "Precompute counts from the normalized token list for efficient probability estimates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8afd37ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unigram counts\n",
    "unigram_counts = Counter(tokens)\n",
    "total_words = len(tokens)\n",
    "\n",
    "# Bigram counts\n",
    "bigram_counts = defaultdict(int)\n",
    "for i in range(len(tokens) - 1):\n",
    "    bigram = (tokens[i], tokens[i + 1])\n",
    "    bigram_counts[bigram] += 1\n",
    "\n",
    "# Trigram counts\n",
    "trigram_counts = defaultdict(int)\n",
    "for i in range(len(tokens) - 2):\n",
    "    trigram = (tokens[i], tokens[i + 1], tokens[i + 2])\n",
    "    trigram_counts[trigram] += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4295f7",
   "metadata": {},
   "source": [
    "### 🧮 Maximum Likelihood Estimation (MLE) for N-Gram Probabilities\n",
    "\n",
    "Estimating probabilities for unigram, bigram, and trigram models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a636f253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_prob(w):\n",
    "    return unigram_counts[w] / total_words if w in unigram_counts else 1e-7  # small smoothing\n",
    "\n",
    "def bigram_prob(w1, w2):\n",
    "    return bigram_counts[(w1, w2)] / unigram_counts[w1] if unigram_counts[w1] > 0 else 0\n",
    "\n",
    "def trigram_prob(w1, w2, w3):\n",
    "    return trigram_counts[(w1, w2, w3)] / bigram_counts[(w1, w2)] if bigram_counts[(w1, w2)] > 0 else 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98709f0a",
   "metadata": {},
   "source": [
    "### 🧩 Sentence Probability Functions for Each N-Gram Model\n",
    "\n",
    "Product of conditional probabilities according to chain rule.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cabb31c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_prob_unigram(sentence):\n",
    "    words = normalize(simple_tokenizer(sentence))\n",
    "    prob = 1.0\n",
    "    for word in words:\n",
    "        prob *= unigram_prob(word)\n",
    "    return prob\n",
    "\n",
    "def sentence_prob_bigram(sentence):\n",
    "    words = normalize(simple_tokenizer(sentence))\n",
    "    if not words:\n",
    "        return 0.0\n",
    "    prob = unigram_prob(words[0])\n",
    "    for i in range(len(words) - 1):\n",
    "        prob *= bigram_prob(words[i], words[i + 1])\n",
    "    return prob\n",
    "\n",
    "def sentence_prob_trigram(sentence):\n",
    "    words = normalize(simple_tokenizer(sentence))\n",
    "    if len(words) < 3:\n",
    "        return sentence_prob_bigram(sentence)\n",
    "    prob = unigram_prob(words[0]) * bigram_prob(words[0], words[1])\n",
    "    for i in range(2, len(words)):\n",
    "        prob *= trigram_prob(words[i - 2], words[i - 1], words[i])\n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d8da3d",
   "metadata": {},
   "source": [
    "### 🔗 Interpolated Sentence Probability (Unigram + Bigram + Trigram)\n",
    "\n",
    "Weights control importance of each level (sum to 1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "741bc7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolated_sentence_prob(sentence, lambda_uni=0.1, lambda_bi=0.3, lambda_tri=0.6):\n",
    "    words = normalize(simple_tokenizer(sentence))\n",
    "    if not words:\n",
    "        return 0.0\n",
    "\n",
    "    if len(words) == 1:\n",
    "        return unigram_prob(words[0])\n",
    "\n",
    "    prob = unigram_prob(words[0])\n",
    "    prob *= lambda_bi * bigram_prob(words[0], words[1]) + lambda_uni * unigram_prob(words[1])\n",
    "\n",
    "    for i in range(2, len(words)):\n",
    "        tri = trigram_prob(words[i - 2], words[i - 1], words[i])\n",
    "        bi = bigram_prob(words[i - 1], words[i])\n",
    "        uni = unigram_prob(words[i])\n",
    "\n",
    "        combined = lambda_tri * tri + lambda_bi * bi + lambda_uni * uni\n",
    "        prob *= combined\n",
    "\n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18b419e",
   "metadata": {},
   "source": [
    "### 🧠 Select Best Prompt From Candidates Using Interpolated N-Gram Scoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ca42360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_prompt_ngram(prompts, lambda_uni=0.1, lambda_bi=0.3, lambda_tri=0.6):\n",
    "    scored = []\n",
    "    for prompt in prompts:\n",
    "        score = interpolated_sentence_prob(prompt, lambda_uni, lambda_bi, lambda_tri)\n",
    "        scored.append((prompt, score))\n",
    "    scored.sort(key=lambda x: x[1], reverse=True)\n",
    "    return {\n",
    "        \"best_prompt\": scored[0][0],\n",
    "        \"scores\": scored\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4efe8bc",
   "metadata": {},
   "source": [
    "### ✅ Example Usage with Prompt Candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ecff26ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best Prompt: How to configure system quickly.\n",
      "\n",
      "📊 Fluency Scores:\n",
      "\"How to configure system quickly.\" → Score: 4.27e-19\n",
      "\"Fast deployment via configuration help.\" → Score: 4.06e-31\n",
      "\"Please provide configuration steps in a fast manner.\" → Score: 5.78e-35\n",
      "\"Assist with server setup guidance to deploy with speed.\" → Score: 1.00e-47\n"
     ]
    }
   ],
   "source": [
    "candidates = [\n",
    "    \"How to configure system quickly.\",\n",
    "    \"Please provide configuration steps in a fast manner.\",\n",
    "    \"Assist with server setup guidance to deploy with speed.\",\n",
    "    \"Fast deployment via configuration help.\"\n",
    "]\n",
    "\n",
    "results = select_best_prompt_ngram(candidates)\n",
    "\n",
    "print(\"✅ Best Prompt:\", results[\"best_prompt\"])\n",
    "print(\"\\n📊 Fluency Scores:\")\n",
    "for prompt, score in results[\"scores\"]:\n",
    "    print(f'\"{prompt}\" → Score: {score:.2e}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006662e7",
   "metadata": {},
   "source": [
    "### 📝 Summary\n",
    "\n",
    "- Added trigram and general N-gram counting to capture more context in language modeling.\n",
    "- Implemented interpolation of unigram, bigram, and trigram scores for robust sentence fluency evaluation.\n",
    "- Provided a reusable function to rank candidate prompts based on this combined model.\n",
    "- This approach is ideal when you have a **large corpus** enabling reliable N-gram probability estimation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa179ef",
   "metadata": {},
   "source": [
    "## 🗣 Student Talking Point: Detailed Explanation for the approach\n",
    "\n",
    "### How Probabilistic N-gram Language Models Support Our Final Project\n",
    "#### In our final project, Sustainable AI:\n",
    " Transparency and Dynamic Data Center Optimization, one key goal of the Optimization & Recommendation Engine is to suggest semantically equivalent but more energy-efficient prompt alternatives for large language model (LLM) inference.\n",
    "\n",
    "Using probabilistic language models—specifically unigram, bigram, trigram, and generalized N-gram models adapted from the lab—we provide a principled mechanism to evaluate the linguistic fluency of candidate prompts generated by the system.\n",
    "\n",
    "Role of N-gram Models in Prompt Optimization\n",
    "\n",
    "#### Fluency scoring:\n",
    "The N-gram models estimate the probability that a given sequence of words (a prompt) appears naturally in real language usage.\n",
    "\n",
    "Unigram models consider individual word frequencies.\n",
    "\n",
    "Bigram models consider pairs of consecutive words.\n",
    "\n",
    "Trigram and higher N-gram models incorporate longer sequences (3 or more consecutive words), modeling more context.\n",
    "\n",
    "#### Filtering candidate prompts:\n",
    "When the engine generates multiple prompt alternatives (candidate rewrites), each candidate is scored using these language models.\n",
    "Prompts with higher combined N-gram probabilities tend to be more natural and fluent, reducing the risk of awkward or unclear phrasing.\n",
    "\n",
    "#### Interpolation and robustness:\n",
    "By combining unigram, bigram, and trigram probabilities with weighted interpolation, the model balances the generality of shorter N-grams with the contextual richness of longer N-grams. This approach makes scoring both reliable and discriminative, even when the corpus data is large but sparse.\n",
    "\n",
    "#### Why Multiple Prompts?\n",
    "The engine does not produce a single optimized prompt blindly it generates several paraphrases to explore different ways to reduce prompt length and computational cost.\n",
    "\n",
    "The probabilistic N-gram models provide a quantitative metric to select the best candidates that maintain linguistic clarity while potentially lowering inference energy.\n",
    "\n",
    "Other modules (semantic similarity, energy cost estimation) work in concert with these language models to ensure meaning preservation and energy efficiency.\n",
    "\n",
    "### Integration Summary\n",
    "Tokenization and normalization prepare prompts for model evaluation.\n",
    "\n",
    "Unigram, bigram, trigram, and N-gram counts are computed on a large training corpus to estimate probabilities.\n",
    "\n",
    "Sentence probability or fluency scores are computed by applying the chain rule using the N-gram models and smoothing by interpolation.\n",
    "\n",
    "The engine ranks prompt candidates by these fluency scores to retain only the most natural and energy-efficient prompts.\n",
    "\n",
    "Lower-probability candidates are filtered out, preventing degraded user experience due to awkward language.\n",
    "\n",
    "### Final Benefit\n",
    "This N-gram based probabilistic fluency scoring component makes your prompt optimization system:\n",
    "\n",
    "More linguistically aware and reliable than naïve length-based heuristics.\n",
    "\n",
    "Able to handle a large variety of prompts, including rare or domain-specific phrases, when combined with a large corpus.\n",
    "\n",
    "A powerful tool in the feedback loop that aligns language generation with environmental sustainability by recommending prompts that save energy without sacrificing clarity or intent.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
