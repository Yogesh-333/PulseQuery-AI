{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "077c6a00",
   "metadata": {},
   "source": [
    "## Training, Saving, and Fine-Tuning Logistic Regression Model for Medical Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc6c2c3",
   "metadata": {},
   "source": [
    "## Adding the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a656339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss\n",
    "from scipy.sparse import hstack, csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4d3597",
   "metadata": {},
   "source": [
    "## Define the medical terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1696f27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEDICAL_TERMS = {\n",
    "    'symptoms': ['pain', 'chest pain', 'shortness of breath', 'nausea', 'vomiting', 'dizziness', 'headache', 'fever', 'fatigue', 'weakness'],\n",
    "    'conditions': ['hypertension', 'diabetes', 'cardiac', 'cardiology', 'emergency', 'diagnosis', 'syndrome', 'disease', 'disorder'],\n",
    "    'demographics': ['patient', 'male', 'female', 'years old', 'age', 'elderly', 'adult', 'pediatric'],\n",
    "    'clinical': ['diagnosis', 'treatment', 'symptoms', 'history', 'complaint', 'medication', 'therapy', 'procedure', 'examination'],\n",
    "    'anatomy': ['heart', 'lung', 'brain', 'kidney', 'liver', 'stomach', 'chest', 'abdomen', 'extremities'],\n",
    "    'medical_specialty': ['cardiology', 'neurology', 'gastroenterology', 'emergency', 'internal medicine', 'surgery'],\n",
    "    'vitals': ['blood pressure', 'heart rate', 'temperature', 'respiratory rate', 'oxygen saturation', 'pulse'],\n",
    "    'assessments': ['workup', 'evaluation', 'assessment', 'monitoring', 'follow-up', 'consultation']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca2bd5f",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "503459f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b007d1",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3231b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_terms(category, k=2):\n",
    "    \"\"\"Sample k terms from a given category.\"\"\"\n",
    "    terms = MEDICAL_TERMS[category]\n",
    "    return random.sample(terms, min(k, len(terms)))\n",
    "\n",
    "def build_sentence():\n",
    "    \"\"\"Build a synthetic medical sentence.\"\"\"\n",
    "    parts = []\n",
    "    parts += sample_terms('demographics', k=1)\n",
    "    parts += sample_terms('clinical', k=1)\n",
    "    parts += sample_terms('anatomy', k=1)\n",
    "    parts += sample_terms('symptoms', k=2)\n",
    "    if random.random() < 0.3:\n",
    "        parts += sample_terms('conditions', k=1)\n",
    "    if random.random() < 0.25:\n",
    "        parts += sample_terms('vitals', k=1)\n",
    "    if random.random() < 0.25:\n",
    "        parts += sample_terms('assessments', k=1)\n",
    "    random.shuffle(parts)\n",
    "    sent = \" \".join(parts)\n",
    "    return f\"{sent}. The {random.choice(['patient','case'])} requires {random.choice(['evaluation','monitoring','assessment','consultation'])}.\"\n",
    "\n",
    "def label_sentence(text):\n",
    "    \"\"\"Label sentence: emergency (1) or not (0).\"\"\"\n",
    "    txt = text.lower()\n",
    "    if 'emergency' in txt or ('chest pain' in txt and 'shortness of breath' in txt):\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2b9f0d",
   "metadata": {},
   "source": [
    "## Create synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1f2cb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2000\n",
    "texts = [build_sentence() for _ in range(N)]\n",
    "labels = [label_sentence(t) for t in texts]\n",
    "df = pd.DataFrame({\"text\": texts, \"label\": labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ba3952",
   "metadata": {},
   "source": [
    "Train - test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "213061d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"text\"], df[\"label\"],\n",
    "    test_size=0.2, random_state=42, stratify=df[\"label\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090639d7",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "974e95ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_category_hits(text_series: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"Count term matches per category.\"\"\"\n",
    "    rows = []\n",
    "    for txt in text_series:\n",
    "        txt_l = txt.lower()\n",
    "        row = {}\n",
    "        for cat, terms in MEDICAL_TERMS.items():\n",
    "            cnt = 0\n",
    "            for term in terms:\n",
    "                pattern = r'\\b' + re.escape(term.lower()) + r'\\b'\n",
    "                cnt += len(re.findall(pattern, txt_l))\n",
    "            row[f'count_{cat}'] = cnt\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def cat_count_transform(X):\n",
    "    if isinstance(X, np.ndarray):\n",
    "        X = pd.Series(X.ravel())\n",
    "    elif isinstance(X, list):\n",
    "        X = pd.Series(X)\n",
    "    return count_category_hits(X)\n",
    "\n",
    "# TF-IDF + counts\n",
    "tfidf = TfidfVectorizer(lowercase=True, ngram_range=(1,2), min_df=2, max_df=0.95)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_train_counts = cat_count_transform(X_train)\n",
    "X_train_full = hstack([X_train_tfidf, csr_matrix(X_train_counts.values)])\n",
    "\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "X_test_counts = cat_count_transform(X_test)\n",
    "X_test_full = hstack([X_test_tfidf, csr_matrix(X_test_counts.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14f7af4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa718bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[After 10 epochs] Test Acc: 0.995 | AUC: 0.999 | LogLoss: 0.0270\n",
      "Saved base model to: ../models\\logreg_sgd_base.joblib\n",
      "[After 20 epochs (fine-tuned)] Test Acc: 0.970 | AUC: 0.998 | LogLoss: 0.0505\n",
      "Saved fine-tuned model to: ../models\\logreg_sgd_finetuned.joblib\n"
     ]
    }
   ],
   "source": [
    "# === Train → Save → Fine-tune → Save-again (SGD Logistic Regression) ===\n",
    "\n",
    "# --- Config ---\n",
    "base_epochs      = 10      # initial training epochs\n",
    "finetune_epochs  = 10      # extra epochs after saving (fine-tuning)\n",
    "batch_size       = 256\n",
    "models_dir       = \"../models\"\n",
    "base_ckpt_path   = os.path.join(models_dir, \"logreg_sgd_base.joblib\")\n",
    "ft_ckpt_path     = os.path.join(models_dir, \"logreg_sgd_finetuned.joblib\")\n",
    "\n",
    "# --- Initialize model (logistic regression via SGD) ---\n",
    "clf = SGDClassifier(loss=\"log_loss\", max_iter=1, learning_rate=\"optimal\", tol=None, random_state=42)\n",
    "classes = np.array([0, 1])\n",
    "\n",
    "n_samples = X_train_full.shape[0]\n",
    "indices = np.arange(n_samples)\n",
    "\n",
    "def train_for_epochs(model, n_epochs):\n",
    "    \"\"\"Train model for n_epochs using mini-batch partial_fit.\"\"\"\n",
    "    for epoch in range(n_epochs):\n",
    "        np.random.shuffle(indices)\n",
    "        for start in range(0, n_samples, batch_size):\n",
    "            batch_idx = indices[start:start+batch_size]\n",
    "            if epoch == 0 and start == 0 and not hasattr(model, \"classes_\"):\n",
    "                model.partial_fit(X_train_full[batch_idx], np.array(y_train)[batch_idx], classes=classes)\n",
    "            else:\n",
    "                model.partial_fit(X_train_full[batch_idx], np.array(y_train)[batch_idx])\n",
    "    return model\n",
    "\n",
    "def eval_model(model, tag=\"\"):\n",
    "    y_pred  = model.predict(X_test_full)\n",
    "    y_proba = model.predict_proba(X_test_full)[:, 1]\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    loss = log_loss(y_test, y_proba, labels=[0,1])\n",
    "    print(f\"[{tag}] Test Acc: {acc:.3f} | AUC: {auc:.3f} | LogLoss: {loss:.4f}\")\n",
    "    return acc, auc, loss\n",
    "\n",
    "# --- 1) Train initial epochs ---\n",
    "clf = train_for_epochs(clf, base_epochs)\n",
    "\n",
    "# --- 2) Evaluate & Save base model ---\n",
    "eval_model(clf, tag=f\"After {base_epochs} epochs\")\n",
    "joblib.dump(clf, base_ckpt_path)\n",
    "print(f\"Saved base model to: {base_ckpt_path}\")\n",
    "\n",
    "# --- 3) Fine-tune (continue training) ---\n",
    "clf = train_for_epochs(clf, finetune_epochs)\n",
    "\n",
    "# --- 4) Evaluate & Save fine-tuned model ---\n",
    "eval_model(clf, tag=f\"After {base_epochs + finetune_epochs} epochs (fine-tuned)\")\n",
    "joblib.dump(clf, ft_ckpt_path)\n",
    "print(f\"Saved fine-tuned model to: {ft_ckpt_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
